{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Hidden Markov Models (HMMs)\n",
    "\n",
    "Here, we will review the foundations that underly HMMs. Specifically, we will review...\n",
    "\n",
    "- Markov chains\n",
    "- Transitional probabilities\n",
    "- Real world examples of Markov chains\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Before we begin looking at HMMs, we must first understand the Markov chain. This is the foundation for HMMs.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Markov chain? \n",
    "\n",
    "A Markov chain is a model of stochasticity. That is, it tells us the likelihood that a state will occur given the previous state. This can be represented mathematically such that $X$ is a state and $n$ is the position of that state in a sequence.\n",
    "\n",
    "$$\n",
    "P(X_{n+1} = x | X_n = x_n)\n",
    "$$\n",
    "\n",
    "However, there are a few important properties that one must keep in mind. Firstly, there exists the property of _forgetfulness_. This means that the future state, in this case, $X_{n+1}$ is purely and only dependent on $X_n$. It is not affected by by states $X_{n-n}$. That is, it is not affected by any previous states other than the immediately preceding state. Secondly, the sum of the weights of transitions within any state $X_n$ is equal to $1$, where $t$ is the weight, as represented by the equation below.\n",
    "\n",
    "$$\n",
    "\\sum{t \\in X_n} = 1\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More down to earth\n",
    "\n",
    "Let's take a look at this in a more understanding way. The most used (and easly explainable) example has to do with the weather.\n",
    "\n",
    "![image](files/intro_weather.png \"Real world\") \n",
    "\n",
    "Here we are looking at a visual representation of the probabilities of weather patterns.\n",
    "\n",
    "Lets say that today is **Rainy**. There is a 0.25 probability that it will be **Sunny** tomorrow and a 0.25 probability that it will be **Cloudy** tomorrow and a 0.50 probability that it will be **Rainy** again tomorrow. These weights along the arrows are called _transition probabilities_ (TPs). Notice that the TPs from each state add up to 1.\n",
    "\n",
    "TPs can be written such that the TPs are function of $i, j, n$\n",
    "\n",
    "$$\n",
    "p_{ij} (n) = P(X_{n+1} = j | X_n = i) \n",
    "$$\n",
    "\n",
    "But how can we implement the equation above into this example? Let's find out.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the visual\n",
    "\n",
    "Let's say that Monday was **Rainy** and Tuesday was also **Rainy** and Wednesday was **Cloudy** and today is **Rainy**. What is the probability that tomorrow will be **Rainy**?\n",
    "\n",
    "Well, we know that tomorrow's weather is _only_ dependant on today's weather. So all we need to look at is the TP from **Rainy** to **Rainy**, which is 0.50!\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing in Python\n",
    "\n",
    "Below is an example of this exact weather problem implemented in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that it will be Rainy tomorrow if today is Sunny is 0.1\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary\n",
    "weather  = {'Sunny':{'Self': 0.30, 'Rainy': 0.10, 'Cloudy': 0.60},\n",
    "            'Rainy':{'Self':0.50, 'Sunny': 0.25, 'Cloudy': 0.25}, \n",
    "            'Cloudy': {'Self': 0.40, 'Sunny': 0.20, 'Rainy': 0.40}\n",
    "}\n",
    "\n",
    "# generate weather patterns\n",
    "week = ['Sunny', 'Rainy', 'Rainy', 'Sunny']\n",
    "\n",
    "# If current state is 'Sunny', what is the probability that tomorrow will be 'Rainy'.\n",
    "previous_state = week[-1] # get the previous state\n",
    "next_state = 'Rainy' # set the next state\n",
    "probability = weather[previous_state][next_state] # find the TP in the dictionary\n",
    "print(f\"The probability that it will be {next_state} tomorrow if today is {previous_state} is {probability}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
